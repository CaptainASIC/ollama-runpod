# Default environment configuration for Ollama RunPod

# Host configuration (needed to expose API on all interfaces)
OLLAMA_HOST=0.0.0.0

# Auto-shutdown configuration (in seconds)
INACTIVITY_TIMEOUT=60

# Uncomment and set your RunPod API key to enable API-based shutdown
# This is more reliable than system shutdown
# RUNPOD_API_KEY=your_runpod_api_key_here

# Logging configuration
LOG_LEVEL=INFO

# Optional pre-loaded models (comma-separated)
# When set, these models will be automatically pulled on startup
# Examples: mistral, llama2, phi, gemma:7b
# PRELOAD_MODELS=mistral,llama2

# Advanced Ollama configuration options
# See https://github.com/ollama/ollama/blob/main/docs/configuration.md
OLLAMA_MODELS=/workspace/models

# Memory usage limits (in MB)
# Lower values save GPU memory but may degrade performance
# OLLAMA_GPU_LAYERS=32

# Pod customization
POD_NAME=Ollama-RunPod